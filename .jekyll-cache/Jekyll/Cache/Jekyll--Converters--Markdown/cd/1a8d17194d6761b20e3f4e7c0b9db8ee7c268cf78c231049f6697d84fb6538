I"2<p>搜索引擎（Search Engine）是指根据一定的策略、运用计算机技术从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务。在日常生活中，可以看到 Google 等 Web 检索网站，还有邮件检索和专利检索等各种应用程序。</p>

<p>在自己写一个搜索引擎之前，需要先了解基本的原理和概念。比如分词，倒排索引，BM25 算法等。可以跟一下 Coursea 的公开课<a href="https://www.coursera.org/course/textretrieval">「Text Retrieval and Search Engines」</a>，<a href="http://book.douban.com/subject/26681675/">「自制搜索引擎」</a>这本书从源码级别分析了搜索引擎的基本原理。</p>

<p>搜索引擎工作步骤分为这几步：</p>

<ul>
  <li>爬虫模块 Crawler 在网页上抓取感兴趣的网页数据存储为 Cached pages</li>
  <li>索引构造器 Indexer 对 Cached pages 处理生成倒排索引(Inverted Index)</li>
  <li>对查询词 Query 在倒排索引中查找对应的文档 Document</li>
  <li>计算 Query 和 Document 的关联度，返回给用户 TopK 个结果</li>
  <li>根据用户点击 TopK 的行为去修正用户查询的 Query，形成反馈闭环。</li>
</ul>

<p>整个项目存放在 <a href="https://github.com/Huangtuzhi/just-search-engine">https://github.com/Huangtuzhi/just-search-engine</a>。</p>

<hr />

<h2 id="组成组件">组成组件</h2>

<p>搜索引擎由下列 4 个组件构成。</p>

<p><img src="/assets/images/search-engine-1.png" alt="图片" /></p>

<ul>
  <li>文档管理器(Document Manager)</li>
  <li>索引构建器(Indexer)</li>
  <li>索引管理器(Index Manager)</li>
  <li>索引检索器(Index Searcher)</li>
</ul>

<p>对应地，在项目结构中</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── just-search-engine
│   ├── documentManager.py # 文档管理器
│   ├── indexer.py         # 索引构建器
│   ├── indexSearcher.py   # 索引检索器
│   ├── README.md          
│   ├── seedbase           # 抓取 WIKI 的 set 对象持久化
│   ├── wiki-postings      # 构建的倒排索引 map 对象持久化
│   ├── text
│   │   └── wiki-result    # 对所有 MongoDB 中的文档统计的结果

</code></pre></div></div>

<hr />

<h2 id="收集文档">收集文档</h2>

<p>我们把抓取的一个网页叫做文档。以 Wikipedia 的网页作为数据源，这些网页数据都是非结构性的，很适合用 MongoDB 来进行存储。</p>

<p>MongoDB 需要依赖 mongodb-server 和 pymongo。安装好之后启动服务器</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mongod --dbpath =/opt/mongodb-data --logpath=/opt/mongodb-data/mongodb.log
</code></pre></div></div>

<p>MongoDB 中有这些字段。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>posting = {
    "DocID": 22223,
    "url": "https://en.wikipedia.org/wiki/Trout",
    "content": "Trout is the common name for a number
     of species of freshwater fish",
    "keyword": "Trout"
}
</code></pre></div></div>

<p>content 存储网页的文字内容。DocID 自增，用来唯一标记文档，和倒排索引中的 DocID 对应，后面在 MongoDB 里也是用这个字段来检索出文字内容。</p>

<hr />

<h2 id="构建倒排索引">构建倒排索引</h2>

<p>构建倒排索引只需要两步</p>

<ul>
  <li>对所有文档进行词频统计，将 &lt;word, DocID, Freq&gt; 写入到二级存储(文本)中</li>
  <li>将文档按照 word 进行合并，构成倒排索引。使用字典存储索引，word 作为 key，[DocID, Freq] 组成的 list 作为 value。</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "search":[[1, 3],[2, 1]],
    "engine":[[2, 1]]
}
</code></pre></div></div>

<p>上面的索引表示：search 这个词在文档 1 中出现 3 次，在文档 2 中出现 1 次。</p>

<p>索引构建完毕之后，使用 pickle 库将索引持久化到二级存储中。</p>

<hr />
<h2 id="检索文档">检索文档</h2>

<p>检索 Query 一般是多个词元组成，如搜索 <code class="language-plaintext highlighter-rouge">popular literature</code>，需要把它分成两个词元
<code class="language-plaintext highlighter-rouge">popular</code> 和 <code class="language-plaintext highlighter-rouge">literature</code> 来处理。</p>

<p>假设 <code class="language-plaintext highlighter-rouge">popular</code> 在倒排索引中的 postings 为 [100, 200, 300]。</p>

<p><code class="language-plaintext highlighter-rouge">literature</code> 在倒排索引中的 postings 为 [233, 300, 400]。</p>

<p>则包含两个词的文档为 300，可以将这个文档返回给用户。</p>

<p>这是在索引中检索一个词元的实现，它返回包含这个词元的 DocID 列表。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def retrive_word(self, word):
    # 找出 DocID 对应的 url
    manager = documentManager()
    collection = manager.connect_mongo()

    id_list = []
    for word in self.word_dictionary[word]:
        url = collection.find_one({"DocID": int(word[0])})["url"]
        id_list.append(int(word[0]))
    return id_list
</code></pre></div></div>

<hr />
<h2 id="文档排名计算-tf-idf">文档排名——计算 TF-IDF</h2>

<p>搜索引擎检索出文档之后，需要选择和查询最相关的文档返回给用户，因此需要对文档进行评估。一般有下列方法：</p>

<ul>
  <li>TF-IDF 词频-逆文档频率</li>
  <li>余弦相似度</li>
  <li>Okapi BM25</li>
</ul>

<p>看一下 TF-IDF 的计算</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def caculate_TFIDF(self, word):
    score_dictionary = {}
    for posting in self.word_dictionary[word]:
        DocID = posting[0]
        freq = posting[1]

        idf = math.log(float(100) / len(self.word_dictionary[word]))
        tf = 1 + math.log(int(freq)) if freq &gt; 0 else 0
        tfidf_score = tf * idf
        score_dictionary[DocID] = tfidf_score
            
    score = sorted(score_dictionary.iteritems(), key=lambda d:d[1], \
    reverse = True)
    print score
</code></pre></div></div>

<p>idf 是文档总数和该词元出现过文档总数的商。TF-IDF 作为衡量“词元在文档集合中是否特殊”的一个指标。</p>

<p>将算得的 TF-IDF 分数存储在字典中，最后按值进行排序。</p>

<hr />

<h2 id="文档排名计算-okapi-bm25">文档排名——计算 Okapi BM25</h2>

<p>TF-IDF 指标得到的是单个查询词的得分，若查询为一句话，可以使用 Okapi BM25 作为评分标准。</p>

<p>BM25 计算公式如下</p>

<p><img src="/assets/images/search-engine-2.png" alt="图片" /></p>

<p>ｃ(w,q) 代表在 Query 中出现某个词元的计数。一般当作 1 处理。</p>

<p>ｃ(w,d) 代表在一个 Document 中出现某个词元的计数。</p>

<table>
  <tbody>
    <tr>
      <td>k(1-b+b</td>
      <td>d</td>
      <td>/avdl) 是对文档长度进行归一化的处理。</td>
    </tr>
  </tbody>
</table>

<p>当查询词为 <code class="language-plaintext highlighter-rouge">popular literature</code>，它会分别计算文档中 <code class="language-plaintext highlighter-rouge">popular</code> 和 <code class="language-plaintext highlighter-rouge">literature</code> 的得分，然后求和，作为这个文档对于查询词的相关性得分。</p>

<hr />

<h2 id="参考">参考</h2>

<p><a href="https://www.coursera.org/course/textretrieval">https://www.coursera.org/course/textretrieval</a></p>

<p><a href="http://book.douban.com/subject/26681675/">自制搜索引擎</a></p>
:ET