---
layout: post
title: "说说机器学习"
description: ""
category: 
tags:
---


这两年机器学习的概念一直很火，无人车、人脸识别、语音识别，似乎无所不能。但有一点被忽略了，“机器学习”算法只是众多算法的一种，和快速排序、red-black BST 一样，它有自己独特的应用场景，而且只能在这个场景中使用。而且请注意，它并不像排序算法一样，可以保证百分之百的可用性，它的边界是有问题的。它更像那些固定算法的一个扩展，机器不用精确去执行程序代码的每一行，在程序以外，它提供给我们一些努力之外的惊喜。

上过「Machine Learning」公开课的人都知道 Andrew Ng，他现在在百度做无人车。个人觉得无人车应用到民用领域还需要漫长的过程，或许得等到人工智能的理论有进展性的突破之后，现在的机器学习算法并不能保证完全的安全可靠性。这些算法更像一个黑盒，通过学习先验知识形成一个黑盒，然后拿着这个“锤子”去到处找“钉子”。当然，人也像一个黑盒，从出生开始不断的学习，建立起完备的知识系统。拿驾照，把车开上五环...(请自行脑补，啊啊啊，五环...)。为什么机器就不能和人一样开上高速公路呢？不是不能，是机器的复杂性和运算能力不够，对复杂环境的处理和预判能力有限。

在「Machine Learning」公开课中，NG 讲了机器学习的入门知识，包括基本的线性代数，概率论，神经网络。机器学习像是基本的数学在工程领域的特定应用。就像吴军在「数学之美」中介绍的 PageRank 算法，布隆过滤器一样。给人的感觉不是复杂，而是简单优雅。罗素好像说过一句话，

> Pure as jade, pure as stone. 

然而好像是我自己编的...

再来看看机器学习算法的典型应用场景。

---------------------------

## 商品购买预测

有这样一个场景：假如你昨天晚上在淘宝上逛，看了一束鲜花(当然是因为今天是...，然而可能并没有什么用...)，你浏览了此商品 100 遍；还有另一个人将此商品加入了购物车。我们可以明显的得出，这两个人今天都有极大可能会买这件商品。

现在淘宝官方给出了上个月 1.14 号到这个月 2.13 号百万用户移动端(手机，平板)的行为数据，包括在淘宝上浏览、收藏、加购物车、购买这四种行为，我们怎么去预测在 2.14 号这一天有多少人，什么人会购买这束鲜花呢？最简单直接的方法是直接预测昨天把鲜花加入购物车的人会买。这样会有一定的准确率，因为加购物车对购买行为来说是很直接的特征。但这种方法不是最优的。不然阿里招算法工程师做甚。

用户的四种行为(浏览、收藏、加购物车、购买)都会对他的后一天的行为产生影响，至于什么影响就要分析数据了。

上面描述的这个场景是阿里的[移动推荐算法竞赛](https://tianchi.aliyun.com/competition/information.htm?spm=5176.100067.5678.2.MsX3h9&raceId=1)。官方给出了百万用户对部分商品的行为数据。我们需要做的是对这些数据建立一个预测模型，然后用这个模型去预测哪个用户购买哪个商品。至于具体的做法，需要了解机器学习算法和特征工程，建议学习公开课「Machine Learning」。细节这里不进行阐述。

做的最好的小组预测的准确率高达 10%，也就是说 100 人中有 10 人会购买这束鲜花。知道这个之后，卖家可以开始补货，结合用户所在地对仓库配额，甚至增加对这些地区的带宽。技术真是生产力啊。

项目地址：[AlibabaRecommand](https://github.com/Huangtuzhi/AlibabaRecommand)

-----------------------------------------

## 作者鉴别

作者鉴别，咦，是不是可以鉴别韩寒的「光明与磊落」是不是原稿？是不是可以去找出某四的「幻城」抄的哪本日本漫画？抱歉，你为什么不去电影院看「澳门风云3」...啊，你在电影院里刷公众号啊...

在学界一般认为(我也这样认为)，「红楼梦」后 40 回并非曹雪芹所著。本文尝试应用机器学习的方法分析原著文本中作者的用词习惯，从技术角度去说明「红楼梦」前 80 回和后 40 回的写作风格差别，继而可以确认后 40 回非原作者所写。

每个作者写作都有自己的用词习惯和风格，即使是故意模仿也会留下很多痕迹。在文言文中，文言虚词(如，之乎者也)分布均匀，书中每个回目都会出现很多文言虚词，差别在于出现频率不同，我们可以把文言虚词的出现频率作为作者的风格特征。

不只文言虚词，还有其他的词在所有回目中出现频率很多。比如对第 80 回进行词频统计，得到这些词的出现次数：

>了:172     的:142     我:70      宝玉:65     你:61      道:54    他:51      也:50      着:48      是:40      说:38

这些高频词汇也可以作为特征。

本文将 20~29 回(诗词曲比较均衡)作为类别 1 的学习样本，将 110~119 回作为类别 2 的学习样本。将两个类别的特征向量输入到 SVM(支持向量机)进行训练得出一个分类模型。再对剩余回目进行分类，看它们分别偏向于哪个类别。SVM 相关原理参见 NG 的公开课 Machine Learning 和 scikit-learn 库。

相关学术论文参见

> 施建军. (2011). 基于支持向量机技术的《 红楼梦》 作者研究. 红楼梦学刊, (5), 35-52.

> 李贤平. (1978).《红楼梦》成书新说. 复旦学报(社会科学版).

运行程序后得到下面的结论

1~80 

```
1   1   1   1   1   2   2   1   1   2   
2   1   1   1   1   1   1   1   1   1   
1   1   1   1   1   1   1   1   1   1   
1   1   1   1   1   1   1   1   1   1   
1   1   1   1   1   1   1   1   1   1   
1   1   1   1   1   1   1   1   1   2   
2   2   1   1   1   1   1   2   1   1   
1   1   1   1   1   1   1   1   1   1 
```

81~120

```
1   1   2   1   1   2   2   1   1   2   
1   2   2   2   2   2   2   1   2   2   
1   2   2   2   2   2   2   1   2   2   
2   2   2   2   2   2   2   2   2   2
```

1 指该回目属于类别 1，2 指该回目属于类别 2。可以得出结论

+ 前 80 回属于一类，后 40 回属于一类
+ 80 回左右是分界点
+ 后 40 回风格不同于前 80 回

81-120 回中有一些被分成了 1 类，这与特征选取有关，还与使用的原著版本有关。这里的版本是网上下的电子版，版本不明，建议使用人民文学出版社 1982 年出版的「红楼梦」作为研究对象。1-80 回有一些被分成了 2 类，可能是后 40 回作者在续写过程中对部分章节进行了修改。

由这两个场景可以更深一层理解机器学习的典型特性。

> 机器学习的重点不在于机器，而在于学习。——
马塞尔·普鲁斯特

项目地址：[reality-of-Dream-of-Red-Mansions](https://github.com/Huangtuzhi/reality-of-Dream-of-Red-Mansions)

----------------------

## 参考 

[UFLDL教程](http://ufldl.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B)

[https://www.coursera.org/learn/machine-learning/](https://www.coursera.org/learn/machine-learning/)
